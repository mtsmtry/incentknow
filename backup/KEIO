名前
KEIO SFC 講義案内
出力コンテンツ
種別
course
フォーマット
出力インデックス
サンプルURL
https://vu.sfc.keio.ac.jp/course_u/data/2020/csec14_10.html





from bs4 import BeautifulSoup, NavigableString
import re
import json
import sys

def scrape(html):
    soup = BeautifulSoup(html, "html.parser", from_encoding="utf-8")
    courses = soup.find_all(class_="course", recursive=True)
    objects = []
 
    for course in courses:
        attrs = {}
        # details
        course_title = course.find(class_="course_title")
        ptn = "([A-Z0-9]+)\\s+(.+?)\\s*(【.*?】)?\\s*(\\(.+\\))?\\s*（(.+?)）"
        match = re.search(ptn, course_title.text)
        if match:
            attrs["id"] = match.group(1)
            attrs["title"] = match.group(2)
            attrs["giga"] = "GIGA" in match.group(4) if match.group(4) else False
            attrs["semester"] = match.group(5)[0]
            if match.group(3):
                if "前半" in match.group(3):
                    attrs["half"] = "前半"
                elif "後半" in match.group(3):
                    attrs["half"] = "後半"
        syllabus = course_title.find("a")
        if syllabus:
            attrs["syllabus"] = syllabus.get("href")
        
        subjectKeyMap = { 
            "関連科目": "related_subjects", 
            "前提科目（推奨）": "recommended_prerequisites",
            "前提科目": "prerequisites"
        }
        #for key in subjectKeyMap.values():
        #    attrs[key] = []

        tbody = course.find("table")
        for row in tbody.find_all("tr", recursive=False):
            tds = row.find_all("td", recursive=False)
            key = tds[0].text.replace(" ", "").replace("　", "")
            if len(tds) >= 2:
                value = tds[1]
                if key == "担当":
                    links = value.find_all("a", recursive=False)
                    persons = []
                    for link in links:
                        url = link.get("href")
                        match = re.search("\+([a-zA-Z0-9]+)$", url)
                        if match:
                            id_ = match.group(1)
                            person = { "id": id_, "url": url, "name": link.text }
                            persons.append(person)
                        else:
                            person = { "id": id_, "name": link.text }
                            persons.append(person)
                    attrs["teachers"] = persons
                elif False: #key in subjectKeyMap:
                    subjects = []
                    for link in value.find_all("a"):
                        url = link.get("href")
                        match = re.match("（(.*?)）\\s*(.*)", link.text)
                        if match:
                            subject = { "url": url, "id": match.group(1), "title": match.group(2) }
                            subjects.append(subject)
                    for child in value.children:
                        if type(child) is NavigableString:
                            text = child.string
                            match = re.search("（(.*?)）\\s*(.*)", text)
                            if match:
                                subject = { "id": match.group(1), "title": match.group(2) }
                                subjects.append(subject)
                    attrs[subjectKeyMap[key]] = subjects
                elif key == "曜日時限":
                    class_texts = value.text.split(",")
                    classes = []
                    for class_text in class_texts:
                        match = re.search("(.+曜日)([１-９]+)時限", class_text)
                        if match:
                            period_text = ord(match.group(2)) - ord('０')
                            class_ = { "day": match.group(1), "period": int(period_text) }
                            classes.append(class_)
                    attrs["classes"] = classes
                elif key == "実施形態":
                    match = re.match("([^（]+).*", value.text)
                    if match:
                        attrs["embodiment"] = match.group(1)
                elif key == "授業形態":
                    attrs["works"] = value.text.split("、")
                elif key == "履修条件":
                    attrs["requirements"] = value.text
                elif key == "前提知識":
                    attrs["required_knowledge"] = value.text
                elif key == "使用言語":
                    attrs["language"] = value.text
                #else:
                #    attrs[key] = tds[1].text
        # summary
        if "id" in attrs:
            summary = soup.find(id="ks"+attrs["id"])
            match = re.search("([0-9])単位", summary.text)
            if match:
                attrs["credit"] = int(match.group(1))
            table = summary.find_next_sibling("table")
            trs = table.find_all("tr") if table else []
            for tr in trs:
                tds = tr.find_all("td")
                key = tds[0]
                value = tds[1]
                if key == "アスペクト":
                    links = value.find_all("a")
                    aspects = []
                    for link in links:
                        aspect = { "url": link.get("href"), "name": link.text }
                        aspects.append(aspect)
                    attrs["aspects"] = aspects
                elif key == "パースペクティブ":
                    link = value.find("a")
                    attrs["perspective"] = { "url": link.get("href"), name: link.text }
        # description
        ps = course.find_all("p", recursive=False)
        lines = []
        for p in ps:
            for line in p.text.split("\n"):
                line = line.strip()
                if len(line) > 0:
                    lines.append(line)
        attrs["description"] = "\n".join(lines)
        
        object_ = { "kind": "course", "data": attrs }
        objects.append(object_)
    result = { "contents": objects, "indexes": [] }
    return result